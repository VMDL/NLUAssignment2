{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU-ASSIGNMENT2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_yTw6IeOtEh"
      },
      "source": [
        "#Utility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmZBHXDweObL"
      },
      "source": [
        "This part of the assignment has been coded in order to describe the mapping from Spacy to Conll, in order to allow the mapping after having readed the file through the function *read_corpus_conll* defined in conll.py which has been imported.\n",
        "\n",
        "The class *Tokenizer* load the vocabulary and describes the tozenization rule which has been implemented by considering as a different word, each part of the sentence separated from another one by a white space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbvFmqqXeAtt"
      },
      "source": [
        "%%capture\n",
        "!wget -c https://github.com/esrel/NLU.Lab.2021/raw/master/src/conll2003.zip\n",
        "!unzip -o ./conll2003.zip\n",
        "!wget -c https://raw.githubusercontent.com/esrel/NLU.Lab.2021/master/src/conll.py\n",
        "\n",
        "import spacy\n",
        "from conll import read_corpus_conll, get_chunks, evaluate\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "spacy_to_conll = {\n",
        "    \"\": \"\",\n",
        "    \"PERSON\": \"PER\",\n",
        "    \"NORP\": \"MISC\",\n",
        "    \"FAC\": \"MISC\",\n",
        "    \"ORG\": \"ORG\",\n",
        "    \"GPE\": \"LOC\",\n",
        "    \"LOC\": \"LOC\",\n",
        "    \"PRODUCT\": \"MISC\",\n",
        "    \"EVENT\": \"MISC\",\n",
        "    \"WORK_OF_ART\": \"MISC\",\n",
        "    \"LAW\": \"MISC\",\n",
        "    \"LANGUAGE\": \"MISC\",\n",
        "    \"DATE\": \"MISC\",\n",
        "    \"TIME\": \"MISC\",\n",
        "    \"PERCENT\": \"MISC\",\n",
        "    \"MONEY\": \"MISC\",\n",
        "    \"QUANTITY\": \"MISC\",\n",
        "    \"ORDINAL\": \"MISC\",\n",
        "    \"CARDINAL\":  \"MISC\",\n",
        "}\n",
        "\n",
        "conll_corpus = read_corpus_conll('test.txt')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "    def __call__(self, text):\n",
        "        words = text.split(\" \")\n",
        "        return Doc(self.vocab, words=words)"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h088A18-AQEm"
      },
      "source": [
        "# Exercise 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bbtZ2GcE_Xc"
      },
      "source": [
        "## Exercise 1.1 - functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WG2dnm2fPl0"
      },
      "source": [
        "Exercise: Evaluate spaCy NER on CoNLL 2003 data (provided): report token-level performance (per class and total) accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o2lI2JHfuOc"
      },
      "source": [
        "The function *true_predicted* takes as input a corpus which is a list of lists of strings, in order to deal with it, according to the description of the Conll2003 dataset and the way how I previously defined the Tokenizer, I iterate over the whole corpus (over each sentence and each element within a sentence) in order to extract from it, both the tokens and the name entities.\n",
        "Tokens and name entities are both appended to a list in order to be used in the following iterative cycle.\n",
        "\n",
        "In the last iterative cycle, for each token extracted from the last sentence, I check if its mapping correspond to the empty string, if is not I append the mapping to its mapping to the IOB code of named entity tag of the current token.\n",
        "\n",
        "Then for each token, I append to the list of prediction, the mapping I have defined and I append to the list of correct label, the name entity tags corresponding to the current token as defined by the Conll2003 dataset.\n",
        "\n",
        "Finally I return the both the list of predictions and the list of correct labels which will be used to evaluate the performances.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3lfY2PdAstn"
      },
      "source": [
        "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "def true_predicted(corpus):\n",
        "  y_pred=[]\n",
        "  y_true=[]\n",
        "  for sentence in corpus:\n",
        "      tokens_list = []\n",
        "      ne_tags_list =[]\n",
        "      for element in sentence:\n",
        "        splitted_el = element[0].split()\n",
        "        tokens_list.append(splitted_el[0])\n",
        "        ne_tags_list.append(splitted_el[3])\n",
        "      doc = nlp(\" \".join(tokens_list))\n",
        "      token_index=0\n",
        "      for token in doc:\n",
        "         ent_iob_conll = token.ent_iob_\n",
        "         if spacy_to_conll[token.ent_type_] != \"\" :\n",
        "            ent_iob_conll += \"-\" + spacy_to_conll[token.ent_type_]\n",
        "         y_pred.append(ent_iob_conll)\n",
        "         y_true.append(ne_tags_list[token_index])\n",
        "         token_index += 1\n",
        "  return (y_pred, y_true)  \n",
        "  "
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHcGl-4niOBo"
      },
      "source": [
        "\n",
        "\n",
        "The function *produce_report* simply print the classification report by using the predicted labels and the correct ones by using the classification report method defined in the library sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTt3RaFqE1hO"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def produce_report(true_label, predicted_label):\n",
        "  print(classification_report(true_label, predicted_label))"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO7_i6KwMm-f"
      },
      "source": [
        "##EXERCISE 1.2 - FUNCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-5fiI8ejHHo"
      },
      "source": [
        "Exercise: Evaluate spaCy NER on CoNLL 2003 data (provided), report CoNLL chunk-level performance (per class and total);\n",
        "precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx2MF-XziioE"
      },
      "source": [
        "The function *produce_report_chunk* receives as input the predicted labels and the correct ones, in order to evaluate them by using the function *evaluate* defined in *conll.py*, then by using the *Pandas* library, it returns a table in order to better visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiAu6LlnMb50"
      },
      "source": [
        "import pandas as pd\n",
        "def produce_report_chunk(true_label, predicted_label):\n",
        "  evaluation = evaluate(true_label, predicted_label)\n",
        "  evaluation_pd = pd.DataFrame().from_dict(evaluation, orient='index')\n",
        "  return evaluation_pd"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SskPIUBbi-9c"
      },
      "source": [
        "The function *true_predicted_chunk* receiving the same input of the previously defined function (*true_predicted*), the first part of the function is the same of *true_predicted*, the main difference is related to the last for, because in this case we are no more dealing with tokens but we are dealing with chunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeJ46676bgT7"
      },
      "source": [
        "def true_predicted_chunk(corpus):\n",
        "  y_pred=[]\n",
        "  y_true=[]\n",
        "  for sentence in corpus:\n",
        "      tokens_list = []\n",
        "      ne_tags_list =[]\n",
        "      for element in sentence:\n",
        "        splitted_el = element[0].split()\n",
        "        tokens_list.append(splitted_el[0])\n",
        "        ne_tags_list.append(splitted_el[3])\n",
        "\n",
        "      doc = nlp(\" \".join(tokens_list))\n",
        "\n",
        "      token_index=0\n",
        "\n",
        "      tmp_pred = []\n",
        "      tmp_true = []\n",
        "      for token in doc:\n",
        "         ent_iob_conll = token.ent_iob_\n",
        "         if spacy_to_conll[token.ent_type_] != \"\" :\n",
        "             ent_iob_conll += \"-\" + spacy_to_conll[token.ent_type_]\n",
        "         tmp_pred.append((token.text,ent_iob_conll))\n",
        "         tmp_true.append((token.text,ne_tags_list[token_index]))\n",
        "         token_index += 1\n",
        "      y_pred.append(tmp_pred)\n",
        "      y_true.append(tmp_true)\n",
        "  return (y_true, y_pred)  "
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngsk3V7CFHLu"
      },
      "source": [
        "## Exercise 1.1 - Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZhIm8xPjo_j"
      },
      "source": [
        "Function for the testing of the *true_predicted* function and the function *produce_report* in order to take the correct labels and the predictions by using *true_predicted* and evaluating the predictions provided with *produce_report*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzToSq61E4Lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f38837-7915-4561-de1f-41805b628929"
      },
      "source": [
        "(true_label, predicted_label)= true_predicted(conll_corpus)\n",
        "produce_report(true_label, predicted_label)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.70      0.78      0.74      1514\n",
            "      B-MISC       0.56      0.11      0.18      3668\n",
            "       B-ORG       0.30      0.50      0.38      1008\n",
            "       B-PER       0.61      0.79      0.69      1253\n",
            "       I-LOC       0.62      0.60      0.61       266\n",
            "      I-MISC       0.40      0.05      0.09      1640\n",
            "       I-ORG       0.52      0.42      0.46      1034\n",
            "       I-PER       0.76      0.82      0.78      1072\n",
            "           O       0.86      0.94      0.90     35211\n",
            "\n",
            "    accuracy                           0.81     46666\n",
            "   macro avg       0.59      0.56      0.54     46666\n",
            "weighted avg       0.79      0.81      0.78     46666\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5AS2OhHj6i3"
      },
      "source": [
        "Function for the testing of the *true_predicted_chunk* function and the function *produce_report_chunk* in order to take the correct labels and the predictions of the chunks by using *true_predicted_chunk* and evaluating the predictions provided with *produce_report_chunk*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8EVzLJ9mKWV"
      },
      "source": [
        "## Exercise 1.2 - Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3wKtQbyW4bN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4440cbc7-7099-490b-b807-5e41a53c2540"
      },
      "source": [
        "chunk_label, chunk_pred= true_predicted_chunk(conll_corpus)\n",
        "evaluation_table = produce_report_chunk(chunk_label, chunk_pred)\n",
        "evaluation_table.round(decimals=2)\n"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.77</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.18</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.45</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          p     r     f     s\n",
              "LOC    0.77  0.70  0.73  1668\n",
              "ORG    0.45  0.27  0.34  1661\n",
              "MISC   0.11  0.55  0.18   702\n",
              "PER    0.76  0.59  0.66  1617\n",
              "total  0.40  0.52  0.45  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r-F5W1uDKYr"
      },
      "source": [
        "#Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQyfjZcuDPPd"
      },
      "source": [
        "## Exercise 2 - functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrjbwUagksXs"
      },
      "source": [
        "EXERCISE: Grouping of Entities. Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WI4ZLY2kVXd"
      },
      "source": [
        "In the following code section, there are defined two functions: *get_list_of_lists* and *get_frequencies*.\n",
        "\n",
        "The first one grouping the entities by extracting all the chunks in the doc.\n",
        "\n",
        "Then we iterate over all entities in the doc, the main principle of the function is based on the boolean *in_chunk* telling us if we are in a chunk or not, based on the fact that it is *False* by default and it gets *True* as we check to be in a chunk, while it is deactived (i.e. it is set to *False) as we check to be out of the chunk where the previous entity (i.e. the entity at the previous iteration) was.\n",
        "\n",
        "The second function *get_frequency* simply iterates over the entire list of list of entities, to count the frequency of each list of entities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8RF4378DMCh"
      },
      "source": [
        "from collections import defaultdict\n",
        "def get_list_of_lists(text = None, doc = None):\n",
        "  if doc == None:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "  #iterate chunk - ents\n",
        "  chunk_list_first =[]\n",
        "  for chunk in doc.noun_chunks:\n",
        "    chunk_list_first.append(chunk.ents)\n",
        "  \n",
        "  list_of_lists = []\n",
        "  chunk_index = 0\n",
        "  in_chunk = False\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    #In this case, the current entity does not belong to a chunk\n",
        "    if (len(chunk_list_first)==0 or len(chunk_list_first)==chunk_index) or (ent not in chunk_list_first[chunk_index]):\n",
        "      list_of_lists.append([ent.label_])\n",
        "      if in_chunk == True:\n",
        "        chunk_index +=1\n",
        "        in_chunk = False\n",
        "    #In this case, the current entity belongs to a chunk\n",
        "    else:\n",
        "      tmp_list=[]\n",
        "      if in_chunk == False:\n",
        "        list_of_lists.append([ent.label_])\n",
        "        in_chunk = True\n",
        "      else:\n",
        "        list_of_lists[chunk_index].append(ent.label_)\n",
        "  return list_of_lists\n",
        "\n",
        "def get_frequencies(list_of_lists):\n",
        "  dict_of_ent = defaultdict(int)\n",
        "  for ent in list_of_lists:\n",
        "      key = str(ent)\n",
        "      dict_of_ent[key] = dict_of_ent[key]+1\n",
        "  return dict_of_ent"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuo9Sq4-lrJU"
      },
      "source": [
        "The function *sort_dict* has been defined only to convert the dictionary of lists into a list of lists to order it based on its value representing the frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSUJVw2SMTXS"
      },
      "source": [
        "def sort_dict(dic):\n",
        "  list_of_freq = dic_of_ent.items()\n",
        "  sorted_list = sorted(list_of_freq, key = lambda x: x[1], reverse=True)\n",
        "  return sorted_list"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tuLGm_QmO17"
      },
      "source": [
        "## Exercise 2 - Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87g0HmfqmTff"
      },
      "source": [
        "Here we simply show how does the previously defined functions work.\n",
        "\n",
        "We take a simple test sentence (\"Apple's Steve Jobs died in 2011 in Palo Alto, California.\"), we group its entities based on the function *get_list_of_lists* then we measure the frequency of each group of entities by exploiting the function *get_frequencies*.\n",
        "\n",
        "Then we sort the dictionary defined by *get_frequency* by using the previously defined function: *sort_dict*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9rfeRaRDgVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a242a27-319c-4d4a-cddb-f5c6d16e4c11"
      },
      "source": [
        "test = \"Apple's Steve Jobs died in 2011 in Palo Alto, California.\"\n",
        "\n",
        "list_of_lists = get_list_of_lists(text=test)\n",
        "print(list_of_lists)\n",
        "dic_of_ent = get_frequencies(list_of_lists)\n",
        "print(\"This is the list of entities and their frequencies\")\n",
        "print(dic_of_ent)\n",
        "\n",
        "print(\"This is the sorted list of entities according to their frequencies\")\n",
        "sorted_list_of_freq = sort_dict(dic_of_ent)\n",
        "print(sorted_list_of_freq)\n"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['ORG', 'PERSON'], ['DATE'], ['GPE'], ['GPE']]\n",
            "This is the list of entities and their frequencies\n",
            "defaultdict(<class 'int'>, {\"['ORG', 'PERSON']\": 1, \"['DATE']\": 1, \"['GPE']\": 2})\n",
            "This is the sorted list of entities according to their frequencies\n",
            "[(\"['GPE']\", 2), (\"['ORG', 'PERSON']\", 1), (\"['DATE']\", 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1_Is00LO7fc"
      },
      "source": [
        "# Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACDIGDBdnPRb"
      },
      "source": [
        "##Exercise 3 - functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoqI8wNTm03q"
      },
      "source": [
        "EXERCISE: One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52yyMg9RnEDL"
      },
      "source": [
        "In the function *post_processing*, given the corpus as input, we compute the preprocessing step already defined in the previous sections, then we iterate over all entities in the current sentence (as we can notice by the way how the iterative cycles are nested), then we store both the list of entities and the list of tokens by appending to them the current entity based on the IOB tag, then for all tokens in list of tokens we have defined.\n",
        "\n",
        "In order to expand the noun compound, we need to find each token having a \"compound\" dependency relation and having the entity type corresponding to the empty string.\n",
        "\n",
        "In order to update the doc, we need to exploit the *set_ents* method of the Spacy class which Set the named entities in the document, considering that the ents correspond to a tuple of Span, we need to define a Span so we need to compute the beginning index and take also the proper label which is the one associated to the current Token (that we have set to the label of the last element in the entity list).\n",
        "\n",
        "It is important to notice that the iterative cycle over the token has been iterated over the children of the token provided by the outer iterative cycle that has been extracted from the list of old entities.\n",
        "\n",
        "Moreover we add the children token which has been processed (so the one of which we have updated the *ent_type_* in order to look into into children if there are further compound dependency relation and noun chunk to be extended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6w4ZpHm8pzM"
      },
      "source": [
        "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "def post_processing(conll_corpus):\n",
        "  for sentence in conll_corpus:\n",
        "    tokens_list = []\n",
        "    for element in sentence:\n",
        "      splitted_el = element[0].split()\n",
        "      tokens_list.append(splitted_el[0])\n",
        "    doc = nlp(\" \".join(tokens_list))\n",
        "    \n",
        "    old_t_list=[] \n",
        "    entities_list = []\n",
        "    for e in doc.ents:\n",
        "      for tok in e:\n",
        "        old_t_list.append(tok)\n",
        "      entities_list.append(e)\n",
        "      for t in old_t_list:\n",
        "        utility =[]\n",
        "        utility.append(t)\n",
        "        for child in t.children:\n",
        "          utility.append(child)\n",
        "        for item in utility:\n",
        "          if item.i == entities_list[-1].start or item.i == entities_list[-1].end-1:\n",
        "            if item.ent_type_ == '' and item.dep_ == 'compound':\n",
        "                item.ent_type_ = entities_list[-1].label_ \n",
        "                old_t_list.append(item)\n",
        "                beg_index = min(entities_list[-1].start, item.i)\n",
        "                end_index = max(entities_list[-1].end-1, item.i)\n",
        "                entities_list[-1] = Span(doc, beg_index, end_index+1, item.ent_type)\n",
        "    doc.set_ents(entities_list)\n"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wr66CFcnKSY"
      },
      "source": [
        "## Exercise 3 - Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEkmIh7ZnXY-"
      },
      "source": [
        "We call the *post_processing* function, previously defined by passing the *conll_corpus* as parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4kZ_4PznK_T"
      },
      "source": [
        "post_processing(conll_corpus)"
      ],
      "execution_count": 240,
      "outputs": []
    }
  ]
}